import streamlit as st
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import requests
import openai
from openai import OpenAI
import os

st.set_page_config(page_title="Simulation Center", layout="wide")

# Title
st.title("ğŸ“Š Economic Simulation Center")

# Language toggle
language = st.radio("ğŸŒ Choose Language / Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

def translate(text_en, text_ar):
    return text_ar if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else text_en

# Sidebar navigation
section = st.sidebar.selectbox(
    translate("Choose Section", "Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø³Ù…"),
    [translate("Microeconomics Simulations", "Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ø¬Ø²Ø¦ÙŠ"),
     translate("Business Math Concepts", "Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„Ø£Ø¹Ù…Ø§Ù„"),
     translate("AI Assistant", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ")]
)

# --- Microeconomics Simulations ---
if section == translate("Microeconomics Simulations", "Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ Ø§Ù„Ø¬Ø²Ø¦ÙŠ"):
    topic = st.sidebar.radio(
        translate("Choose Topic", "Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹"),
        [translate("Supply and Demand", "Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø·Ù„Ø¨"),
         translate("Elasticities", "Ø§Ù„Ù…Ø±ÙˆÙ†Ø§Øª"),
         translate("Production & Costs", "Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ"),
         translate("Oligopoly (Game Theory)", "Ø§Ø­ØªÙƒØ§Ø± Ø§Ù„Ù‚Ù„Ø© (Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨)"),
         translate("Competitive Market", "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠ"),
         translate("Monopolistic Competition", "Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø§Ù„Ø§Ø­ØªÙƒØ§Ø±ÙŠØ©")]
    )

    if topic == translate("Supply and Demand", "Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø·Ù„Ø¨"):
        st.header(translate("Supply and Demand Simulation", "Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø·Ù„Ø¨"))

        price = st.slider(translate("Price", "Ø§Ù„Ø³Ø¹Ø±"), 1, 100, 50)
        demand_intercept = st.number_input(translate("Demand Intercept (a)", "ØªÙ‚Ø§Ø·Ø¹ Ø§Ù„Ø·Ù„Ø¨ (a)"), value=100)
        demand_slope = st.number_input(translate("Demand Slope (b)", "Ù…ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ (b)"), value=1)
        supply_intercept = st.number_input(translate("Supply Intercept (c)", "ØªÙ‚Ø§Ø·Ø¹ Ø§Ù„Ø¹Ø±Ø¶ (c)"), value=20)
        supply_slope = st.number_input(translate("Supply Slope (d)", "Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ (d)"), value=1)

        quantity_demanded = demand_intercept - demand_slope * price
        quantity_supplied = supply_intercept + supply_slope * price

        st.metric(translate("Quantity Demanded", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"), quantity_demanded)
        st.metric(translate("Quantity Supplied", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©"), quantity_supplied)

        st.subheader(translate("Real Case: Qatari Wheat Market (2022)", "Ø­Ø§Ù„Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©: Ø³ÙˆÙ‚ Ø§Ù„Ù‚Ù…Ø­ Ø§Ù„Ù‚Ø·Ø±ÙŠ (2022)"))
        st.markdown(translate(
            "In 2022, Qatar imported large quantities of wheat at a stable world price. Local demand shifts during Ramadan caused excess demand. The simulation above mimics how small changes in price affect market balance.",
            "ÙÙŠ Ø¹Ø§Ù… 2022ØŒ Ø§Ø³ØªÙˆØ±Ø¯Øª Ù‚Ø·Ø± ÙƒÙ…ÙŠØ§Øª ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù‚Ù…Ø­ Ø¨Ø³Ø¹Ø± Ø¹Ø§Ù„Ù…ÙŠ Ø«Ø§Ø¨Øª. Ø£Ø¯Øª Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø®Ù„Ø§Ù„ Ø±Ù…Ø¶Ø§Ù† Ø¥Ù„Ù‰ ÙØ§Ø¦Ø¶ Ø·Ù„Ø¨. ØªØ­Ø§ÙƒÙŠ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø£Ø¹Ù„Ø§Ù‡ ÙƒÙŠÙ ØªØ¤Ø«Ø± Ø§Ù„ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø·ÙÙŠÙØ© ÙÙŠ Ø§Ù„Ø³Ø¹Ø± Ø¹Ù„Ù‰ ØªÙˆØ§Ø²Ù† Ø§Ù„Ø³ÙˆÙ‚."
        ))

    elif topic == translate("Elasticities", "Ø§Ù„Ù…Ø±ÙˆÙ†Ø§Øª"):
        st.header(translate("Elasticity of Demand", "Ù…Ø±ÙˆÙ†Ø© Ø§Ù„Ø·Ù„Ø¨"))
        initial_price = st.number_input(translate("Initial Price", "Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ"), value=10.0)
        new_price = st.number_input(translate("New Price", "Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯"), value=12.0)
        initial_quantity = st.number_input(translate("Initial Quantity", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©"), value=100.0)
        new_quantity = st.number_input(translate("New Quantity", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"), value=90.0)

        try:
            elasticity = ((new_quantity - initial_quantity) / initial_quantity) / ((new_price - initial_price) / initial_price)
            st.metric(translate("Price Elasticity", "Ù…Ø±ÙˆÙ†Ø© Ø§Ù„Ø³Ø¹Ø±"), round(elasticity, 2))
        except ZeroDivisionError:
            st.error(translate("Price or quantity cannot be zero.", "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø³Ø¹Ø± Ø£Ùˆ Ø§Ù„ÙƒÙ…ÙŠØ© ØµÙØ±Ø§Ù‹."))

        st.subheader(translate("Real Case: iPhone Price Sensitivity", "Ø­Ø§Ù„Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©: Ø­Ø³Ø§Ø³ÙŠØ© Ø³Ø¹Ø± Ø§Ù„Ø¢ÙŠÙÙˆÙ†"))
        st.markdown(translate(
            "Apple increased iPhone prices by 10% in 2023. In emerging markets, quantity sold dropped by ~12%, suggesting an elasticity of -1.2.",
            "Ø²Ø§Ø¯Øª Ø´Ø±ÙƒØ© Apple Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø¢ÙŠÙÙˆÙ† Ø¨Ù†Ø³Ø¨Ø© 10Ùª ÙÙŠ Ø¹Ø§Ù… 2023. ÙÙŠ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ù†Ø§Ø´Ø¦Ø©ØŒ Ø§Ù†Ø®ÙØ¶Øª Ø§Ù„ÙƒÙ…ÙŠØ§Øª Ø§Ù„Ù…Ø¨Ø§Ø¹Ø© Ø¨Ù†Ø³Ø¨Ø© 12Ùª ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø±ÙˆÙ†Ø© -1.2."
        ))

    elif topic == translate("Production & Costs", "Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ"):
        st.header(translate("Production and Cost Functions", "Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙˆØ§Ù„ØªÙƒÙ„ÙØ©"))

        labor = st.slider(translate("Labor Input", "Ø§Ù„Ø¹Ù…Ø§Ù„Ø©"), 1, 100, 50)
        capital = st.slider(translate("Capital Input", "Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„"), 1, 100, 50)

        output = labor ** 0.5 * capital ** 0.5
        cost = 20 * labor + 30 * capital

        st.metric(translate("Output (Q)", "Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Q)"), round(output, 2))
        st.metric(translate("Total Cost", "Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©"), round(cost, 2))

        st.subheader(translate("Real Case: Tesla Factory Efficiency", "Ø­Ø§Ù„Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©: ÙƒÙØ§Ø¡Ø© Ù…ØµÙ†Ø¹ ØªØ³Ù„Ø§"))
        st.markdown(translate(
            "Tesla's Shanghai Gigafactory uses automation (capital) and specialized labor. Increasing capital improves output at diminishing marginal returns.",
            "ÙŠØ³ØªØ®Ø¯Ù… Ù…ØµÙ†Ø¹ ØªØ³Ù„Ø§ ÙÙŠ Ø´Ù†ØºÙ‡Ø§ÙŠ Ø§Ù„Ø£ØªÙ…ØªØ© (Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„) ÙˆØ§Ù„Ø¹Ù…Ø§Ù„Ø© Ø§Ù„Ù…ØªØ®ØµØµØ©. ØªØ¤Ø¯ÙŠ Ø²ÙŠØ§Ø¯Ø© Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø¨Ù…Ø±Ø¯ÙˆØ¯ Ù‡Ø§Ù…Ø´ÙŠ Ù…ØªÙ†Ø§Ù‚Øµ."
        ))

    elif topic == translate("Oligopoly (Game Theory)", "Ø§Ø­ØªÙƒØ§Ø± Ø§Ù„Ù‚Ù„Ø© (Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨)"):
        st.header(translate("Cournot Competition Simulation", "Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ù…ÙˆØ°Ø¬ ÙƒÙˆØ±Ù†Ùˆ"))

        q1 = st.slider(translate("Firm 1 Quantity", "ÙƒÙ…ÙŠØ© Ø§Ù„Ø´Ø±ÙƒØ© 1"), 0, 100, 30)
        q2 = st.slider(translate("Firm 2 Quantity", "ÙƒÙ…ÙŠØ© Ø§Ù„Ø´Ø±ÙƒØ© 2"), 0, 100, 30)

        total_q = q1 + q2
        price = max(0, 100 - total_q)
        profit1 = (price - 20) * q1
        profit2 = (price - 20) * q2

        st.metric("Price", price)
        st.metric("Profit Firm 1", profit1)
        st.metric("Profit Firm 2", profit2)

        st.subheader(translate("Real Case: Airbus vs Boeing Market Competition", "Ø­Ø§Ù„Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©: Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø¨ÙŠÙ† Ø¥ÙŠØ±Ø¨Ø§Øµ ÙˆØ¨ÙˆÙŠÙ†Øº"))
        st.markdown(translate(
            "Boeing and Airbus often restrict output to keep prices high, much like the Cournot model shows.",
            "ØªÙ‚ÙˆÙ… Ø´Ø±ÙƒØªØ§ Ø¨ÙˆÙŠÙ†Øº ÙˆØ¥ÙŠØ±Ø¨Ø§Øµ Ø¨ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ø±ØªÙØ¹Ø©ØŒ ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…Ø§ ÙŠÙˆØ¶Ø­ Ù†Ù…ÙˆØ°Ø¬ ÙƒÙˆØ±Ù†Ùˆ."
        ))

    elif topic == translate("Competitive Market", "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠ"):
        st.header(translate("Competitive Market Simulation", "Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠ"))

        market_price = st.slider(translate("Market Price", "Ø³Ø¹Ø± Ø§Ù„Ø³ÙˆÙ‚"), 1, 100, 50)
        cost_per_unit = st.number_input(translate("Cost per Unit", "Ø§Ù„ØªÙƒÙ„ÙØ© Ù„ÙƒÙ„ ÙˆØ­Ø¯Ø©"), value=30)
        quantity = st.slider(translate("Quantity Produced", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ù†ØªØ¬Ø©"), 1, 100, 10)

        profit = (market_price - cost_per_unit) * quantity
        st.metric(translate("Profit", "Ø§Ù„Ø±Ø¨Ø­"), profit)

        quantities = np.arange(1, 101)
        revenues = market_price * quantities
        costs = cost_per_unit * quantities

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=quantities, y=revenues, mode='lines', name=translate("Total Revenue", "Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯ Ø§Ù„ÙƒÙ„ÙŠ"), line=dict(color='green')))
        fig.add_trace(go.Scatter(x=quantities, y=costs, mode='lines', name=translate("Total Cost", "Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ÙƒÙ„ÙŠØ©"), line=dict(color='red')))
        fig.add_trace(go.Scatter(x=[quantity], y=[market_price * quantity], mode='markers', name=translate("Chosen Quantity", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"), marker=dict(size=10, color='blue')))

        fig.update_layout(
            title=translate("Revenue and Cost in Competitive Market", "Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯ ÙˆØ§Ù„ØªÙƒÙ„ÙØ© ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠ"),
            xaxis_title=translate("Quantity", "Ø§Ù„ÙƒÙ…ÙŠØ©"),
            yaxis_title=translate("Amount", "Ø§Ù„Ù‚ÙŠÙ…Ø©"),
            legend_title=translate("Legend", "Ø§Ù„Ù…ÙØªØ§Ø­")
        )

        st.plotly_chart(fig)

    elif topic == translate("Monopolistic Competition", "Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø§Ù„Ø§Ø­ØªÙƒØ§Ø±ÙŠØ©"):
        st.header(translate("Monopolistic Competition Simulation", "Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø§Ù„Ø§Ø­ØªÙƒØ§Ø±ÙŠØ©"))

        price = st.slider(translate("Product Price", "Ø³Ø¹Ø± Ø§Ù„Ù…Ù†ØªØ¬"), 1, 100, 50)
        avg_cost = st.number_input(translate("Average Cost", "Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©"), value=40)
        quantity = st.slider(translate("Quantity Sold", "Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø¨Ø§Ø¹Ø©"), 1, 100, 10)
        differentiation = st.slider(translate("Product Differentiation Level", "Ø¯Ø±Ø¬Ø© ØªÙ…ÙŠØ² Ø§Ù„Ù…Ù†ØªØ¬"), 0, 10, 5)

        revenue = price * quantity
        total_cost = avg_cost * quantity
        profit = revenue - total_cost + differentiation * 5

        st.metric(translate("Profit", "Ø§Ù„Ø±Ø¨Ø­"), profit)

        diff_range = np.arange(0, 11)
        profits = [(price * quantity - avg_cost * quantity + d * 5) for d in diff_range]

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=diff_range,
            y=profits,
            mode='lines+markers',
            name=translate("Profit", "Ø§Ù„Ø±Ø¨Ø­"),
            line=dict(color='purple')
        ))

        fig.update_layout(
            title=translate("Profit vs Product Differentiation", "Ø§Ù„Ø±Ø¨Ø­ Ù…Ù‚Ø§Ø¨Ù„ Ø¯Ø±Ø¬Ø© ØªÙ…ÙŠØ² Ø§Ù„Ù…Ù†ØªØ¬"),
            xaxis_title=translate("Product Differentiation Level", "Ø¯Ø±Ø¬Ø© Ø§Ù„ØªÙ…ÙŠØ²"),
            yaxis_title=translate("Profit", "Ø§Ù„Ø±Ø¨Ø­"),
            legend_title=translate("Legend", "Ø§Ù„Ù…ÙØªØ§Ø­")
        )

        st.plotly_chart(fig)

st.title("ğŸ§  AI Economics Assistant (Mistral-7B)")

api_key = st.text_input("ğŸ”‘ Enter your Together AI API Key", type="password")
prompt = st.text_area("ğŸ’¬ Ask a question:", height=150)

if st.button("Generate Answer"):
    if not api_key:
        st.error("âŒ Please enter your API key.")
    elif not prompt.strip():
        st.error("âŒ Please write a prompt.")
    else:
        url = "https://api.together.xyz/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "mistralai/Mistral-7B-Instruct-v0.2",  # âœ… Update this with your chosen model
            "messages": [
                {"role": "system", "content": "You are an expert in economics."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 1024
        }

        try:
            resp = requests.post(url, headers=headers, json=payload)
            if resp.status_code == 200:
                answer = resp.json()["choices"][0]["message"]["content"]
                st.markdown("### ğŸ¤– Answer")
                st.write(answer)
            else:
                st.error(f"âŒ HTTP {resp.status_code}: {resp.json()}")
        except Exception as e:
            st.error(f"âŒ Error: {e}")
 # Additional Features Below (do not change original block)

        # Allow user to adjust temperature and max_tokens dynamically
        with st.expander("ğŸ”§ Advanced Settings"):
            user_temp = st.slider("Temperature (creativity)", 0.0, 1.0, 0.7, 0.05)
            user_max_tokens = st.slider("Max tokens (response length)", 256, 4096, 1024, 128)

        payload["temperature"] = user_temp
        payload["max_tokens"] = user_max_tokens

        # Optional: Let the user pick a model from supported options
        with st.expander("ğŸ§  Model Options"):
            available_models = [
                "mistralai/Mistral-7B-Instruct-v0.2",
                "mistralai/Mixtral-8x7B-Instruct-v0.1",
                "meta-llama/Llama-2-7b-chat-hf"
            ]
            selected_model = st.selectbox("Choose a model", available_models, index=0)
            payload["model"] = selected_model

        # Show full JSON request payload for debugging or transparency
        with st.expander("ğŸ“¦ Show Request Payload"):
            st.json(payload)

        # Button to re-run the same query
        if st.button("ğŸ” Re-run"):
            try:
                resp = requests.post(url, headers=headers, json=payload)
                if resp.status_code == 200:
                    answer = resp.json()["choices"][0]["message"]["content"]
                    st.markdown("### ğŸ¤– Answer")
                    st.write(answer)
                else:
                    st.error(f"âŒ HTTP {resp.status_code}: {resp.json()}")
            except Exception as e:
                st.error(f"âŒ Error: {e}")
 # --- ğŸ“‚ File Upload for Context (RAG-style) ---
        with st.expander("ğŸ“„ Upload File for Context"):
            uploaded_file = st.file_uploader("Upload a text/PDF file", type=["txt", "pdf"])
            if uploaded_file:
                import PyPDF2
                if uploaded_file.name.endswith(".pdf"):
                    reader = PyPDF2.PdfReader(uploaded_file)
                    file_text = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
                else:
                    file_text = uploaded_file.read().decode("utf-8")
                st.success("âœ… File uploaded and processed.")
                st.text_area("ğŸ“œ Extracted Content", file_text[:1000] + "..." if len(file_text) > 1000 else file_text)
                payload["messages"].insert(-1, {
                    "role": "system",
                    "content": f"Use the following document as context:\n{file_text[:3000]}"
                })

        # --- ğŸ§  Answer Summarization ---
        with st.expander("ğŸ“ Summarize Answer"):
            if st.button("ğŸ” Summarize the previous answer"):
                summary_payload = {
                    "model": selected_model,
                    "messages": [
                        {"role": "system", "content": "Summarize the following answer clearly and concisely."},
                        {"role": "user", "content": answer}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 200
                }
                try:
                    sum_resp = requests.post(url, headers=headers, json=summary_payload)
                    if sum_resp.status_code == 200:
                        summary = sum_resp.json()["choices"][0]["message"]["content"]
                        st.markdown("### âœ‚ï¸ Summary")
                        st.write(summary)
                    else:
                        st.error("âŒ Failed to summarize.")
                except Exception as e:
                    st.error(f"âŒ Error: {e}")

        # --- ğŸ’¾ Download Output ---
        with st.expander("â¬‡ï¸ Download Answer"):
            st.download_button("ğŸ“¥ Download Answer as TXT", answer, file_name="ai_answer.txt")

        # --- ğŸ’¬ Chat History / Memory ---
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []
        st.session_state.chat_history.append({"question": payload['messages'][-1]['content'], "answer": answer})
        with st.expander("ğŸ•“ Chat History"):
            for i, entry in enumerate(st.session_state.chat_history):
                st.markdown(f"**Q{i+1}:** {entry['question']}")
                st.markdown(f"**A{i+1}:** {entry['answer']}")

             # --- ğŸŒ Translate Answer ---
        with st.expander("ğŸŒ Translate the Response"):
            st.markdown("#### Choose a target language:")
            col1, col2 = st.columns([3, 1])
            with col1:
                target_lang = st.selectbox(
                    "Language",
                    ["French", "Arabic", "Spanish", "German", "Chinese", "Italian", "Portuguese"]
                )
            with col2:
                do_translate = st.button("ğŸ” Translate", use_container_width=True)

            if do_translate:
                if not answer:
                    st.warning("â— Nothing to translate yet. Ask a question first.")
                else:
                    translation_instruction = f"Translate the following text to {target_lang}:\n\n{answer}"

                    translation_payload = {
                        "model": selected_model,
                        "messages": [
                            {"role": "user", "content": translation_instruction}
                        ],
                        "temperature": 0.5,
                        "max_tokens": 1024
                    }

                    try:
                        trans_resp = requests.post(url, headers=headers, json=translation_payload)
                        if trans_resp.status_code == 200:
                            translated_text = trans_resp.json()["choices"][0]["message"]["content"]
                            st.success(f"âœ… Translated to {target_lang}:")
                            st.write(translated_text)
                        else:
                            st.error(f"âŒ HTTP {trans_resp.status_code}: {trans_resp.json()}")
                    except Exception as e:
                        st.error(f"âŒ Translation error: {e}")
